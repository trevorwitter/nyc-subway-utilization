{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87123e9-c3bd-453b-8326-115cf2621d4e",
   "metadata": {},
   "source": [
    "# Seq2Seq setup\n",
    "[example here](https://www.kaggle.com/code/omershect/learning-pytorch-seq2seq-with-m5-data-set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b74c7cfc-025a-4dc5-82ee-ab35f3ee445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import (\n",
    "    train_model,\n",
    "    preprocess_data, \n",
    "    SequenceDataset, \n",
    "    score_model, \n",
    "    predict,\n",
    "    get_predictions,\n",
    "    plot_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ade53b0-2f43-4139-ab2a-ac565ec00fb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16800, 704)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"../data/mta_subway_221231_100wk_dbscan.parquet\"\n",
    "df = pd.read_parquet(filename)\n",
    "df = df.fillna(0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9018cc4a-1ec3-430a-a9c7-2b36b4b01c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "097ea847-20ce-4f9c-ad1c-65716d13b38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 704)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test, features = preprocess_data(df)\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e08f491b-9e51-4fc9-aedd-b499ef729298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceDataset(\n",
    "        df_train,\n",
    "        #target=None,\n",
    "        features=features,\n",
    "        sequence_length=336,\n",
    "        horizon_length=168,\n",
    "        forecast_lead=1\n",
    "        )\n",
    "test_dataset = SequenceDataset(\n",
    "        df_test,\n",
    "        #target=None,\n",
    "        features=features,\n",
    "        sequence_length=336,\n",
    "        horizon_length=168,\n",
    "        forecast_lead=1\n",
    "        )\n",
    "# Need to set up SequenceDataset to take output length as an arguement \n",
    "#to specify y sequence length\n",
    "\n",
    "# Currently only returns next single row, want to set up to take rows for each hour \n",
    "#over next week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c86b979-956e-4604-94b3-b5653de8091c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9957fd81-7f62-423d-9aed-a6e9e0f1e0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear((enc_hid_dim) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias= False)\n",
    "    \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        batch_size = encoder_outputs.shape[0]\n",
    "        src_len = encoder_outputs.shape[1]\n",
    "        print(hidden.shape)\n",
    "        hidden = hidden[2:3, :, :]\n",
    "        hidden = hidden.repeat(1, src_len, 1)\n",
    "        print(f\"attention hidden shape: {hidden.shape}\")\n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim=2)))\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        return F.softmax(attention, dim=1)\n",
    "    \n",
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, seq_len, attention, input_dim, num_features, encoder_hidden_state = 512, dropout=0):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.attention = attention\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = input_dim\n",
    "        self.num_features = num_features\n",
    "        self.dropout=dropout\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=encoder_hidden_state + 1, \n",
    "            hidden_size=input_dim,\n",
    "            num_layers=3,\n",
    "            batch_first=True,\n",
    "            dropout=self.dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(self.hidden_dim * 2, self.num_features)\n",
    "\n",
    "    def forward(self, x, input_h, input_c, encoder_outputs):\n",
    "        a = self.attention(input_h, encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        x = x.reshape((1,1,1))\n",
    "        rnn_input = torch.cat((x, weighted), dim = 2)\n",
    "        x, (hn, cn) = self.lstm(rnn_input, (input_h, input_c))\n",
    "        output = x.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        x = self.linear(torch.cat((output, weighted), dim=1))\n",
    "        return x, hn, cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76b3d1e-aeab-4ceb-a72b-df3a9d29622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, window, num_features, hidden_units, embedding_dim=64, num_layers=1,dropout=0):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.window = window\n",
    "        self.num_features = num_features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_features,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers,\n",
    "            dropout=self.dropout\n",
    "        )\n",
    "            \n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        #x = x.reshape((1, self.window, self.num_features))\n",
    "        #h_1 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_units))\n",
    "        \n",
    "        h0 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_())\n",
    "        c0 = Variable(torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_())\n",
    "        x, (h, c) = self.lstm(x, (h0, c0))\n",
    "        #print(f\"encoder x shape: {x.shape}\")\n",
    "        #print(f\"encoder h shape: {h.shape}\")\n",
    "        #print(f\"encoder c shape: {c.shape}\")\n",
    "        return x, (h, c)\n",
    "\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, seq_len, input_dim, num_features, dropout=0):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = input_dim\n",
    "        self.num_features = num_features\n",
    "        self.dropout=dropout\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.num_features, \n",
    "            hidden_size=input_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=self.dropout\n",
    "        )\n",
    "        self.linear = nn.Linear(self.hidden_dim, self.num_features)\n",
    "\n",
    "    def forward(self, x, input_h, input_c):\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.reshape((batch_size,1,self.num_features))\n",
    "        x, (hn, cn) = self.lstm(x, (input_h, input_c))\n",
    "        x = self.linear(x)\n",
    "        return x, hn, cn\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, num_features, window, horizon, hidden_units, num_layers=1, dropout=0):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.window = window\n",
    "        self.horizon = horizon\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        #self.attention = Attention(64,64)\n",
    "        self.encoder = Encoder(\n",
    "            window=self.window,\n",
    "            num_features=self.num_features,\n",
    "            hidden_units=self.hidden_units, \n",
    "            num_layers=self.num_layers, \n",
    "            dropout=self.dropout\n",
    "            )\n",
    "        #self.decoder = AttentionDecoder(\n",
    "        #    seq_len=window,\n",
    "        #    attention=self.attention,\n",
    "        #    input_dim=64,\n",
    "        #    num_features=self.num_features,\n",
    "        #    \n",
    "        #    dropout=self.dropout\n",
    "        #    #input is output state of encoder\n",
    "        #    #output length is equal to specified horizon length\n",
    "        #    )\n",
    "        self.decoder = Decoder(\n",
    "            seq_len=self.window, \n",
    "            input_dim=self.hidden_units, \n",
    "            num_features=self.num_features\n",
    "            )\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        #o,(h,c) = self.encoder(x, (h0, c0))\n",
    "        o,(h,c) = self.encoder(x)\n",
    "        targets_ta = []\n",
    "        prev_output = x[:,-1,:].unsqueeze(1)\n",
    "        for horizon_step in range(self.horizon):\n",
    "            prev_x, prev_h, prev_c = self.decoder(prev_output,h, c)\n",
    "            targets_ta.append(prev_x.reshape((batch_size, 1, self.num_features)))\n",
    "            h, c = prev_h, prev_c\n",
    "            prev_output = prev_x\n",
    "        targets = torch.stack(targets_ta).squeeze(2)\n",
    "        targets = targets.reshape(batch_size,self.horizon, self.num_features)\n",
    "        return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3050410-df40-448e-ba3c-c68fc495cff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(\n",
    "    num_features=len(features), \n",
    "    window=336, \n",
    "    horizon=168, \n",
    "    hidden_units=16\n",
    ")\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a196ce-80c1-4314-b09a-aefd5ae4ebfe",
   "metadata": {},
   "source": [
    "rewrite `train_model()` to output whole sequence of length `horizion`\n",
    "\n",
    "\n",
    "`avg_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e12f7ea-4cf2-46b5-94af-78b720d24b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9b66009-ea07-4608-adbb-f9e8d5cdb786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 336, 704])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# [batch size, window length, number of features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "269749df-ab11-4d41-abe7-16789ec35de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 168, 704])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = model(X)\n",
    "pred_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf556c16-2c97-4deb-82dc-c29156b71343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([168, 704])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef3a20aa-b81e-4407-8815-fdcfb9b11f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 168, 704])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe5fdd62-8cf1-4fdb-9d8a-5d22e8421e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0738, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_function(pred_y, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "380e0689-81be-4071-8de8-00b58c11d3e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0236536163091658"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_loss = train_model(\n",
    "    train_loader, \n",
    "    model, \n",
    "    loss_function, \n",
    "    optimizer\n",
    ")\n",
    "avg_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
