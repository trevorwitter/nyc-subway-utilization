INFO: 2022-11-12 10:20:51,915: Epoch: 0
INFO: 2022-11-12 10:21:05,056: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2022-11-12 10:21:05,057: Epoch: 1
INFO: 2022-11-12 10:21:18,146: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2022-11-12 10:21:18,147: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2022-11-12 10:25:56,266: Epoch: 0
INFO: 2022-11-12 10:26:09,420: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2022-11-12 10:26:09,420: Epoch: 1
INFO: 2022-11-12 10:26:22,694: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2022-11-12 10:26:22,694: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2022-11-12 10:43:20,638: Epoch: 0
INFO: 2022-11-12 10:43:29,386: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2022-11-12 10:43:29,386: Epoch: 1
INFO: 2022-11-12 10:43:38,162: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2022-11-12 10:43:38,163: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2022-11-12 10:44:22,056: Epoch: 0
INFO: 2022-11-12 10:44:35,270: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2022-11-12 10:44:35,271: Epoch: 1
INFO: 2022-11-12 10:44:48,469: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2022-11-12 10:44:48,469: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2022-12-15 19:22:47,080: Epoch: 0
INFO: 2022-12-15 19:23:00,194: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2022-12-15 19:23:00,194: Epoch: 1
INFO: 2022-12-15 19:23:13,272: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2022-12-15 19:23:13,275: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2022-12-16 11:28:53,561: Epoch: 0
INFO: 2022-12-16 11:29:01,998: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2022-12-16 11:29:01,998: Epoch: 1
INFO: 2022-12-16 11:29:10,430: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2022-12-16 11:29:10,432: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 16:40:34,153: Epoch: 0
INFO: 2023-02-12 16:40:43,261: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2023-02-12 16:40:43,261: Epoch: 1
INFO: 2023-02-12 16:40:52,383: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2023-02-12 16:40:52,384: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 16:45:30,444: Epoch: 0
INFO: 2023-02-12 16:45:39,971: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2023-02-12 16:45:39,971: Epoch: 1
INFO: 2023-02-12 16:45:49,232: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2023-02-12 16:45:49,233: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 16:47:24,838: Epoch: 0
INFO: 2023-02-12 16:47:34,171: Epoch 0 -- Train Loss: 0.8522270637450213; Test Loss: 0.7313036869444642
INFO: 2023-02-12 16:47:34,171: Epoch: 1
INFO: 2023-02-12 16:47:43,493: Epoch 1 -- Train Loss: 0.623198502519605; Test Loss: 0.6555235624604081
INFO: 2023-02-12 16:47:43,494: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 16:57:12,410: Epoch: 0
INFO: 2023-02-12 16:57:22,088: Epoch 0 -- Train Loss: nan; Test Loss: nan
INFO: 2023-02-12 16:57:22,088: Epoch: 1
INFO: 2023-02-12 16:57:31,639: Epoch 1 -- Train Loss: nan; Test Loss: nan
INFO: 2023-02-12 16:57:31,641: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 17:02:52,150: Epoch: 0
INFO: 2023-02-12 17:03:00,644: Epoch 0 -- Train Loss: nan; Test Loss: nan
INFO: 2023-02-12 17:03:00,644: Epoch: 1
INFO: 2023-02-12 17:03:08,812: Epoch 1 -- Train Loss: nan; Test Loss: nan
INFO: 2023-02-12 17:03:08,813: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 17:15:28,815: Epoch: 0
INFO: 2023-02-12 17:15:38,883: Epoch 0 -- Train Loss: nan; Test Loss: nan
INFO: 2023-02-12 17:15:38,883: Epoch: 1
INFO: 2023-02-12 17:15:48,513: Epoch 1 -- Train Loss: nan; Test Loss: nan
INFO: 2023-02-12 17:15:48,514: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 17:21:45,004: Epoch: 0
INFO: 2023-02-12 17:21:53,971: Epoch 0 -- Train Loss: 0.8718910930516786; Test Loss: 1568.8477250125745
INFO: 2023-02-12 17:21:53,971: Epoch: 1
INFO: 2023-02-12 17:22:02,920: Epoch 1 -- Train Loss: 0.5832752620011772; Test Loss: 1568.654299785818
INFO: 2023-02-12 17:22:02,921: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 17:23:43,426: Epoch: 0
INFO: 2023-02-12 17:23:52,411: Epoch 0 -- Train Loss: 0.8718910930516786; Test Loss: 1568.8477250125745
INFO: 2023-02-12 17:23:52,411: Epoch: 1
INFO: 2023-02-12 17:24:01,399: Epoch 1 -- Train Loss: 0.5832752620011772; Test Loss: 1568.654299785818
INFO: 2023-02-12 17:24:01,400: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 17:35:18,559: Epoch: 0
INFO: 2023-02-12 17:35:37,398: Epoch: 0
INFO: 2023-02-12 17:35:46,122: Epoch 0 -- Train Loss: 0.8718910930516786; Test Loss: 1568.8477250125745
INFO: 2023-02-12 17:35:46,122: Epoch: 1
INFO: 2023-02-12 17:35:54,705: Epoch 1 -- Train Loss: 0.5832752620011772; Test Loss: 1568.654299785818
INFO: 2023-02-12 17:35:54,706: model saved to: models/LSTM_16unit_1layer_30seq.pt
INFO: 2023-02-12 17:37:41,448: Epoch: 0
INFO: 2023-02-12 17:37:45,586: Epoch 0 -- Train Loss: 0.870232959446453; Test Loss: 1563.2218493844782
INFO: 2023-02-12 17:37:45,586: Epoch: 1
INFO: 2023-02-12 17:37:49,578: Epoch 1 -- Train Loss: 0.59145574846438; Test Loss: 1562.992738170567
INFO: 2023-02-12 17:37:49,580: model saved to: models/LSTM_64unit_1layer_30seq.pt
INFO: 2023-02-12 17:39:20,168: Epoch: 0
INFO: 2023-02-12 17:39:26,167: Epoch 0 -- Train Loss: 0.8717903273446219; Test Loss: 1563.2633433668386
INFO: 2023-02-12 17:39:26,167: Epoch: 1
INFO: 2023-02-12 17:39:32,254: Epoch 1 -- Train Loss: 0.5846463145244689; Test Loss: 1563.0256021777789
INFO: 2023-02-12 17:39:32,254: Epoch: 2
INFO: 2023-02-12 17:39:38,325: Epoch 2 -- Train Loss: 0.4821550507630621; Test Loss: 1562.9137442259562
INFO: 2023-02-12 17:39:38,325: Epoch: 3
INFO: 2023-02-12 17:39:44,278: Epoch 3 -- Train Loss: 0.430984991079285; Test Loss: 1562.8479077052502
INFO: 2023-02-12 17:39:44,278: Epoch: 4
INFO: 2023-02-12 17:39:50,196: Epoch 4 -- Train Loss: 0.39409297094458623; Test Loss: 1562.8089820103985
INFO: 2023-02-12 17:39:50,198: model saved to: models/LSTM_64unit_2layer_30seq.pt
INFO: 2023-02-12 17:40:28,936: Epoch: 0
INFO: 2023-02-12 17:40:35,440: Epoch 0 -- Train Loss: 0.8717903273446219; Test Loss: 1563.2633433668386
INFO: 2023-02-12 17:40:35,440: Epoch: 1
INFO: 2023-02-12 17:40:41,903: Epoch 1 -- Train Loss: 0.5846463145244689; Test Loss: 1563.0256021777789
INFO: 2023-02-12 17:40:41,903: Epoch: 2
INFO: 2023-02-12 17:40:48,354: Epoch 2 -- Train Loss: 0.4821550507630621; Test Loss: 1562.9137442259562
INFO: 2023-02-12 17:40:48,354: Epoch: 3
INFO: 2023-02-12 17:40:54,800: Epoch 3 -- Train Loss: 0.430984991079285; Test Loss: 1562.8479077052502
INFO: 2023-02-12 17:40:54,800: Epoch: 4
INFO: 2023-02-12 17:41:01,268: Epoch 4 -- Train Loss: 0.39409297094458623; Test Loss: 1562.8089820103985
INFO: 2023-02-12 17:41:01,270: model saved to: models/LSTM_64unit_2layer_30seq.pt
INFO: 2023-02-12 17:42:55,159: Epoch: 0
INFO: 2023-02-12 17:43:02,123: Epoch 0 -- Train Loss: 0.8717903273446219; Test Loss: 1563.2633433668386
INFO: 2023-02-12 17:43:02,123: Epoch: 1
INFO: 2023-02-12 17:43:09,007: Epoch 1 -- Train Loss: 0.5846463145244689; Test Loss: 1563.0256021777789
INFO: 2023-02-12 17:43:09,007: Epoch: 2
INFO: 2023-02-12 17:43:16,146: Epoch 2 -- Train Loss: 0.4821550507630621; Test Loss: 1562.9137442259562
INFO: 2023-02-12 17:43:16,146: Epoch: 3
INFO: 2023-02-12 17:43:23,030: Epoch 3 -- Train Loss: 0.430984991079285; Test Loss: 1562.8479077052502
INFO: 2023-02-12 17:43:23,030: Epoch: 4
INFO: 2023-02-12 17:43:29,903: Epoch 4 -- Train Loss: 0.39409297094458623; Test Loss: 1562.8089820103985
INFO: 2023-02-12 17:43:29,905: model saved to: models/LSTM_64unit_2layer_30seq.pt
INFO: 2023-02-12 17:43:50,040: Epoch: 0
INFO: 2023-02-12 17:43:55,947: Epoch 0 -- Train Loss: 0.8717903273446219; Test Loss: 1563.2633433668386
INFO: 2023-02-12 17:43:55,947: Epoch: 1
INFO: 2023-02-12 17:44:01,787: Epoch 1 -- Train Loss: 0.5846463145244689; Test Loss: 1563.0256021777789
INFO: 2023-02-12 17:44:01,787: Epoch: 2
INFO: 2023-02-12 17:44:07,629: Epoch 2 -- Train Loss: 0.4821550507630621; Test Loss: 1562.9137442259562
INFO: 2023-02-12 17:44:07,629: Epoch: 3
INFO: 2023-02-12 17:44:13,476: Epoch 3 -- Train Loss: 0.430984991079285; Test Loss: 1562.8479077052502
INFO: 2023-02-12 17:44:13,476: Epoch: 4
INFO: 2023-02-12 17:44:19,313: Epoch 4 -- Train Loss: 0.39409297094458623; Test Loss: 1562.8089820103985
INFO: 2023-02-12 17:44:19,315: model saved to: models/LSTM_64unit_2layer_30seq.pt
INFO: 2023-02-12 17:47:23,569: Epoch: 0
INFO: 2023-02-12 17:47:30,086: Epoch 0 -- Train Loss: 0.8717903273446219; Test Loss: 1563.2633433668386
INFO: 2023-02-12 17:47:30,086: Epoch: 1
INFO: 2023-02-12 17:47:36,533: Epoch 1 -- Train Loss: 0.5846463145244689; Test Loss: 1563.0256021777789
INFO: 2023-02-12 17:47:36,533: Epoch: 2
INFO: 2023-02-12 17:47:42,953: Epoch 2 -- Train Loss: 0.4821550507630621; Test Loss: 1562.9137442259562
INFO: 2023-02-12 17:47:42,953: Epoch: 3
INFO: 2023-02-12 17:47:49,396: Epoch 3 -- Train Loss: 0.430984991079285; Test Loss: 1562.8479077052502
INFO: 2023-02-12 17:47:49,396: Epoch: 4
INFO: 2023-02-12 17:47:55,849: Epoch 4 -- Train Loss: 0.39409297094458623; Test Loss: 1562.8089820103985
INFO: 2023-02-12 17:47:55,851: model saved to: models/LSTM_64unit_2layer_30seq.pt
